{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db7825e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric_temporal.nn import TGCN\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import dask.dataframe as dd\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import networkx as nx\n",
    "from torch_geometric.utils import to_networkx\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score # ROC-AUC için gerekli kütüphaneler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0295c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device: NVIDIA GeForce GTX 1050 Ti\n"
     ]
    }
   ],
   "source": [
    "# Set device to GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"CUDA is not available, using CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23818776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data paths\n",
    "edges_train_path = \"edges_train_A.csv\"\n",
    "node_features_path = \"node_features_sampled.csv\"\n",
    "edge_type_features_path = \"edge_type_features.csv\"\n",
    "input_a_path = \"input_A_initial.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d0de350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading edges_train_df with Dask...\n"
     ]
    }
   ],
   "source": [
    "# --- Optimized Data Loading with Dask ---\n",
    "print(\"Loading edges_train_df with Dask...\")\n",
    "edges_train_ddf = dd.read_csv(\n",
    "    edges_train_path,\n",
    "    header=None,\n",
    "    skiprows=1,\n",
    "    sep=\"\\t\",\n",
    "    blocksize=\"16MB\",\n",
    "    assume_missing=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92ee94f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating node mapping from training data...\n",
      "Total number of unique nodes in training data: 19442\n"
     ]
    }
   ],
   "source": [
    "# --- Create Node Mapping from Training Data Only ---\n",
    "print(\"\\nCreating node mapping from training data...\")\n",
    "train_nodes = pd.concat([\n",
    "    edges_train_ddf[0].str.split(\",\", n=3, expand=True)[0].compute().astype(\"int32\"),\n",
    "    edges_train_ddf[0].str.split(\",\", n=3, expand=True)[1].compute().astype(\"int32\")\n",
    "]).unique()\n",
    "num_nodes = len(train_nodes)\n",
    "print(f\"Total number of unique nodes in training data: {num_nodes}\")\n",
    "\n",
    "node_mapping = {node_id: idx for idx, node_id in enumerate(train_nodes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "65dafd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_edges_partition(partition):\n",
    "    try:\n",
    "        split_df = partition.iloc[:, 0].str.split(\",\", n=3, expand=True)\n",
    "        if split_df.shape[1] == 4:\n",
    "            split_df.columns = [\"src_id\", \"dst_id\", \"edge_type\", \"timestamp\"]\n",
    "            for col in [\"src_id\", \"dst_id\", \"edge_type\", \"timestamp\"]:\n",
    "                split_df[col] = pd.to_numeric(split_df[col], errors=\"coerce\").fillna(-1).astype(\"int32\")\n",
    "            split_df[\"src_id\"] = split_df[\"src_id\"].map(node_mapping).fillna(-1).astype(\"int32\")\n",
    "            split_df[\"dst_id\"] = split_df[\"dst_id\"].map(node_mapping).fillna(-1).astype(\"int32\")\n",
    "            split_df = split_df[\n",
    "                (split_df[\"src_id\"] >= 0) & \n",
    "                (split_df[\"dst_id\"] >= 0) & \n",
    "                (split_df[\"src_id\"] < num_nodes) & \n",
    "                (split_df[\"dst_id\"] < num_nodes)\n",
    "            ]\n",
    "            if split_df.empty:\n",
    "                print(\"Warning: Partition is empty after filtering.\")\n",
    "            return split_df\n",
    "        else:\n",
    "            print(f\"Warning: Partition has {split_df.shape[1]} columns, expected 4.\")\n",
    "            return pd.DataFrame(columns=[\"src_id\", \"dst_id\", \"edge_type\", \"timestamp\"], dtype=\"int32\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing partition: {e}\")\n",
    "        return pd.DataFrame(columns=[\"src_id\", \"dst_id\", \"edge_type\", \"timestamp\"], dtype=\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9311bca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edges_train_ddf partitions: 44\n"
     ]
    }
   ],
   "source": [
    "meta_edges = {\"src_id\": \"int32\", \"dst_id\": \"int32\", \"edge_type\": \"int32\", \"timestamp\": \"int32\"}\n",
    "edges_train_ddf = edges_train_ddf.map_partitions(process_edges_partition, meta=meta_edges)\n",
    "edges_train_ddf = edges_train_ddf[[\"src_id\", \"dst_id\", \"edge_type\", \"timestamp\"]].persist()\n",
    "print(\"edges_train_ddf partitions:\", edges_train_ddf.npartitions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "004356d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After mapping - Max src_id (train): 19439, Max dst_id (train): 19441\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "311"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_src = edges_train_ddf[\"src_id\"].max().compute()\n",
    "max_dst = edges_train_ddf[\"dst_id\"].max().compute()\n",
    "print(f\"After mapping - Max src_id (train): {max_src}, Max dst_id (train): {max_dst}\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "055395b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading node_features_df with Pandas (chunked)...\n"
     ]
    }
   ],
   "source": [
    "# --- Load Node Features in Chunks ---\n",
    "print(\"\\nLoading node_features_df with Pandas (chunked)...\")\n",
    "def load_node_features_chunked(file_path, chunksize=10000):\n",
    "    node_features_list = []\n",
    "    for chunk in pd.read_csv(file_path, header=None, skiprows=1, sep=\"\\t\", chunksize=chunksize):\n",
    "        split_df = chunk.iloc[:, 0].str.split(\",\", expand=True)\n",
    "        split_df.columns = [\"node_id\"] + [f\"feature_{i}\" for i in range(split_df.shape[1] - 1)]\n",
    "        split_df[\"node_id\"] = pd.to_numeric(split_df[\"node_id\"], errors=\"coerce\").fillna(-1).astype(\"int32\")\n",
    "        for col in split_df.columns[1:]:\n",
    "            split_df[col] = pd.to_numeric(split_df[col], errors=\"coerce\").fillna(0).astype(\"float32\")\n",
    "        node_features_list.append(split_df)\n",
    "        gc.collect()\n",
    "    return pd.concat(node_features_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4750e94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_features_df shape: (19441, 9)\n"
     ]
    }
   ],
   "source": [
    "node_features_df = load_node_features_chunked(node_features_path)\n",
    "print(\"node_features_df shape:\", node_features_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d7430cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node_features_df shape after mapping: (19441, 9)\n"
     ]
    }
   ],
   "source": [
    "node_features_df[\"node_id\"] = node_features_df[\"node_id\"].map(node_mapping).fillna(-1).astype(\"int32\")\n",
    "node_features_df = node_features_df[node_features_df[\"node_id\"] >= 0]\n",
    "print(\"node_features_df shape after mapping:\", node_features_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5e1f7c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node features tensor shape: torch.Size([19442, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_features_tensor = torch.zeros((num_nodes, node_features_df.shape[1] - 1), dtype=torch.float32)\n",
    "known_nodes = node_features_df[\"node_id\"].dropna().astype(int)\n",
    "node_features_values = node_features_df.drop(columns=[\"node_id\"]).values\n",
    "node_features_values = (node_features_values - node_features_values.mean(axis=0)) / (node_features_values.std(axis=0) + 1e-8)\n",
    "for idx, node_id in enumerate(known_nodes):\n",
    "    if 0 <= node_id < num_nodes:\n",
    "        node_features_tensor[node_id] = torch.tensor(node_features_values[idx], dtype=torch.float32)\n",
    "print(f\"Node features tensor shape: {node_features_tensor.shape}\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f72f1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading edge_type_features_df with Pandas (chunked)...\n"
     ]
    }
   ],
   "source": [
    "# --- Load Edge Type Features in Chunks ---\n",
    "print(\"\\nLoading edge_type_features_df with Pandas (chunked)...\")\n",
    "def load_edge_type_features_chunked(file_path, chunksize=10000):\n",
    "    edge_type_features_list = []\n",
    "    for chunk in pd.read_csv(file_path, header=None, skiprows=1, sep=\"\\t\", chunksize=chunksize):\n",
    "        split_df = chunk.iloc[:, 0].str.split(\",\", expand=True)\n",
    "        split_df.columns = [\"edge_type\"] + [f\"feature_{i}\" for i in range(split_df.shape[1] - 1)]\n",
    "        split_df[\"edge_type\"] = pd.to_numeric(split_df[\"edge_type\"], errors=\"coerce\").fillna(-1).astype(\"int32\")\n",
    "        for col in split_df.columns[1:]:\n",
    "            split_df[col] = pd.to_numeric(split_df[col], errors=\"coerce\").fillna(0).astype(\"float32\")\n",
    "        edge_type_features_list.append(split_df)\n",
    "        gc.collect()\n",
    "    return pd.concat(edge_type_features_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92c5be7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edge_type_features_df shape: (247, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_type_features_df = load_edge_type_features_chunked(edge_type_features_path)\n",
    "print(\"edge_type_features_df shape:\", edge_type_features_df.shape)\n",
    "edge_features_values = edge_type_features_df.drop(columns=[\"edge_type\"]).values\n",
    "edge_features_values = (edge_features_values - edge_features_values.mean(axis=0)) / (edge_features_values.std(axis=0) + 1e-8)\n",
    "edge_type_features_df.iloc[:, 1:] = edge_features_values\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bda59ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading input_a_df with Pandas...\n"
     ]
    }
   ],
   "source": [
    "# --- Load Input Data ---\n",
    "print(\"\\nLoading input_a_df with Pandas...\")\n",
    "def process_input_a(df):\n",
    "    split_df = df.iloc[:, 0].str.split(\",\", expand=True)\n",
    "    split_df.columns = [\"src_id\", \"dst_id\", \"edge_type\", \"start_time\", \"end_time\", \"label\"]  # 6 sütun\n",
    "    for col in split_df.columns:\n",
    "        split_df[col] = pd.to_numeric(split_df[col], errors=\"coerce\").fillna(-1).astype(\"int32\")\n",
    "    return split_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba1dc92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_a_df shape: (8196, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_a_df = pd.read_csv(input_a_path, header=None, skiprows=1, sep=\"\\t\")\n",
    "input_a_df = process_input_a(input_a_df)\n",
    "print(\"input_a_df shape:\", input_a_df.shape)\n",
    "input_a_df[\"src_id\"] = input_a_df[\"src_id\"].map(node_mapping).fillna(-1).astype(\"int32\")\n",
    "input_a_df[\"dst_id\"] = input_a_df[\"dst_id\"].map(node_mapping).fillna(-1).astype(\"int32\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2e27907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Temporal Graph Creation ---\n",
    "def create_temporal_graph_dask(edges_ddf, node_features_tensor, edge_type_features_df):\n",
    "    temporal_data = []\n",
    "    edge_type_features_tensor = torch.tensor(\n",
    "        edge_type_features_df.drop(columns=[\"edge_type\"]).values, dtype=torch.float32\n",
    "    ).to(device)\n",
    "    edge_type_to_idx = {et: idx for idx, et in enumerate(edge_type_features_df[\"edge_type\"])}\n",
    "\n",
    "    timestamp_groups = edges_ddf.groupby(\"timestamp\").size().compute().index.sort_values()\n",
    "    sampled_timestamps = timestamp_groups[::200]  # 10'da bir örnekleme, yaklaşık 2251 snapshot\n",
    "    print(f\"Total timestamps: {len(timestamp_groups)}, Sampled timestamps: {len(sampled_timestamps)}\")\n",
    "\n",
    "    for timestamp in tqdm(sampled_timestamps, desc=\"Creating snapshots\"):\n",
    "        group = edges_ddf[edges_ddf[\"timestamp\"] == timestamp][[\"src_id\", \"dst_id\", \"edge_type\"]].compute()\n",
    "        if not group.empty:\n",
    "            group = group[(group[\"src_id\"] >= 0) & (group[\"dst_id\"] >= 0) & (group[\"src_id\"] < num_nodes) & (group[\"dst_id\"] < num_nodes)]\n",
    "            if not group.empty:\n",
    "                edge_index = torch.tensor(group[[\"src_id\", \"dst_id\"]].values, dtype=torch.long).t().to(device)\n",
    "                max_index = edge_index.max().item()\n",
    "                if max_index >= num_nodes:\n",
    "                    print(f\"Error: Snapshot at timestamp {timestamp} has max index {max_index}, expected < {num_nodes}\")\n",
    "                    continue\n",
    "                edge_types = group[\"edge_type\"].values\n",
    "                edge_attr = torch.zeros((edge_index.shape[1], edge_type_features_tensor.shape[1]), dtype=torch.float32, device=device)\n",
    "                for i, et in enumerate(edge_types):\n",
    "                    if et in edge_type_to_idx:\n",
    "                        edge_attr[i] = edge_type_features_tensor[edge_type_to_idx[et]]\n",
    "                data = Data(\n",
    "                    x=node_features_tensor.to(device),\n",
    "                    edge_index=edge_index,\n",
    "                    edge_attr=edge_attr,\n",
    "                    t=int(timestamp),\n",
    "                    num_nodes=num_nodes\n",
    "                )\n",
    "                temporal_data.append(data)\n",
    "            else:\n",
    "                print(f\"Warning: Snapshot at timestamp {timestamp} is empty after filtering.\")\n",
    "        del group\n",
    "        gc.collect()\n",
    "    \n",
    "    #del edge_type_features_tensor\n",
    "    gc.collect()\n",
    "    return temporal_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff8a9831",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating temporal graph with Dask...\n",
      "Total timestamps: 22510, Sampled timestamps: 113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating snapshots: 100%|██████████| 113/113 [01:20<00:00,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NUMBER OF TEMPORAL SNAPSHOTS: 113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCreating temporal graph with Dask...\")\n",
    "temporal_graph_sequence = create_temporal_graph_dask(\n",
    "    edges_train_ddf, node_features_tensor, edge_type_features_df\n",
    ")\n",
    "print(f\"NUMBER OF TEMPORAL SNAPSHOTS: {len(temporal_graph_sequence)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6e5986c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#del edges_train_ddf\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8797fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Pre-generate Negative Samples for Efficiency ---\n",
    "def pre_generate_negative_samples(temporal_data, num_nodes, num_samples_per_snapshot=1000):\n",
    "    neg_samples_cache = []\n",
    "    for current_graph in tqdm(temporal_data, desc=\"Pre-generating negative samples\"):\n",
    "        edge_index = current_graph.edge_index.cpu()\n",
    "        neg_edges = []\n",
    "        attempts = 0\n",
    "        max_attempts = num_samples_per_snapshot * 10\n",
    "        while len(neg_edges) < num_samples_per_snapshot and attempts < max_attempts:\n",
    "            src = np.random.randint(0, num_nodes)\n",
    "            dst = np.random.randint(0, num_nodes)\n",
    "            if src != dst and not torch.any((edge_index[0] == src) & (edge_index[1] == dst)):\n",
    "                neg_edges.append([src, dst])\n",
    "            attempts += 1\n",
    "        neg_edges_tensor = torch.tensor(neg_edges, dtype=torch.long).t().to(device)\n",
    "        neg_samples_cache.append(neg_edges_tensor)\n",
    "    return neg_samples_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7978bd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Improved Model with Dropout ---\n",
    "class TemporalLinkPredictor(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_edge_features, hidden_channels=64, dropout_rate=0.7):\n",
    "        super(TemporalLinkPredictor, self).__init__()\n",
    "        self.initial_fc = torch.nn.Linear(num_node_features, hidden_channels)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "        self.tgcn = TGCN(in_channels=hidden_channels, out_channels=hidden_channels)\n",
    "        self.edge_fc = torch.nn.Linear(num_edge_features, hidden_channels)\n",
    "        self.linear = torch.nn.Linear(hidden_channels * 2, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, src_ids, dst_ids):\n",
    "        h = F.relu(self.initial_fc(x))\n",
    "        h = self.dropout(h)\n",
    "        h = F.relu(self.tgcn(h, edge_index))\n",
    "        edge_h = F.relu(self.edge_fc(edge_attr))\n",
    "        edge_h_agg = torch.zeros((num_nodes, self.tgcn.out_channels), device=x.device, dtype=torch.float16)\n",
    "        edge_h_agg.index_add_(0, src_ids, edge_h.to(torch.float16))\n",
    "        edge_h_agg.index_add_(0, dst_ids, edge_h.to(torch.float16))\n",
    "        degree = torch.bincount(edge_index[0], minlength=num_nodes).clamp(min=1).float().to(x.device)\n",
    "        edge_h_agg = edge_h_agg.to(torch.float32) / degree.view(-1, 1)\n",
    "        h = torch.cat([h, edge_h_agg], dim=-1)\n",
    "        out = self.linear(h)  # Logit çıktılar\n",
    "        out_pairs = out[src_ids]\n",
    "        return out_pairs.squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "16a7b7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "num_node_features = temporal_graph_sequence[0].x.shape[1] if temporal_graph_sequence else 0\n",
    "num_edge_features = temporal_graph_sequence[0].edge_attr.shape[1] if temporal_graph_sequence else 0\n",
    "model = TemporalLinkPredictor(num_node_features, num_edge_features, dropout_rate=0.3).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
    "pos_weight = torch.tensor([0.1], device=device)\n",
    "criterion = torch.nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "scaler = GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3d49135c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pre-generating negative samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pre-generating negative samples: 100%|██████████| 113/113 [00:04<00:00, 26.49it/s]\n"
     ]
    }
   ],
   "source": [
    "# Pre-generate negative samples\n",
    "print(\"\\nPre-generating negative samples...\")\n",
    "neg_samples_cache = pre_generate_negative_samples(temporal_graph_sequence, num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "09bcd97c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Training with Positive and Negative Samples ---\n",
    "def train(model, temporal_data, neg_samples_cache, optimizer, criterion, batch_size=64):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    num_nodes = temporal_data[0].x.shape[0]\n",
    "    \n",
    "    for i in range(0, len(temporal_data) - 1, batch_size):\n",
    "        batch_data = temporal_data[i:i + batch_size]\n",
    "        batch_neg_samples = neg_samples_cache[i:i + batch_size]\n",
    "        optimizer.zero_grad()\n",
    "        batch_loss = 0\n",
    "        for idx, current_graph in enumerate(batch_data):\n",
    "            if current_graph.edge_index.numel() > 0 and current_graph.x is not None:\n",
    "                x = current_graph.x.to(device)\n",
    "                edge_index = current_graph.edge_index.to(device)\n",
    "                edge_attr = current_graph.edge_attr.to(device)\n",
    "                \n",
    "                pos_edges = edge_index.t()[:min(200, edge_index.shape[1])]\n",
    "                if pos_edges.shape[0] == 0:\n",
    "                    continue\n",
    "                pos_src = pos_edges[:, 0]\n",
    "                pos_dst = pos_edges[:, 1]\n",
    "                pos_labels = torch.ones(pos_src.shape[0], device=device)\n",
    "                \n",
    "                neg_edges = batch_neg_samples[idx]\n",
    "                if neg_edges.shape[1] == 0:\n",
    "                    continue\n",
    "                neg_edges = neg_edges[:, :pos_src.shape[0]]  # Negatif örnek sayısını pozitifle eşitle\n",
    "                neg_src = neg_edges[0]\n",
    "                neg_dst = neg_edges[1]\n",
    "                neg_labels = torch.zeros(neg_src.shape[0], device=device)\n",
    "                \n",
    "                src_ids = torch.cat([pos_src, neg_src])\n",
    "                dst_ids = torch.cat([pos_dst, neg_dst])\n",
    "                labels = torch.cat([pos_labels, neg_labels])\n",
    "                \n",
    "                valid_mask = (src_ids < num_nodes) & (dst_ids < num_nodes)\n",
    "                if valid_mask.sum() == 0:\n",
    "                    continue\n",
    "                src_ids = src_ids[valid_mask]\n",
    "                dst_ids = dst_ids[valid_mask]\n",
    "                labels = labels[valid_mask]\n",
    "                if len(src_ids) == 0:\n",
    "                    continue\n",
    "                \n",
    "                batch_size = len(src_ids)\n",
    "                edge_indices = torch.zeros(batch_size, dtype=torch.long, device=device)\n",
    "                for i in range(batch_size):\n",
    "                    src, dst = src_ids[i].item(), dst_ids[i].item()\n",
    "                    edge_idx = (edge_index[0] == src) & (edge_index[1] == dst)\n",
    "                    if edge_idx.any():\n",
    "                        edge_indices[i] = edge_idx.nonzero(as_tuple=True)[0][0]\n",
    "                    else:\n",
    "                        edge_indices[i] = -1\n",
    "                edge_attr_batch = torch.zeros((batch_size, num_edge_features), dtype=torch.float32, device=device)\n",
    "                valid_edge_mask = edge_indices >= 0\n",
    "                edge_attr_batch[valid_edge_mask] = edge_attr[edge_indices[valid_edge_mask]]\n",
    "                \n",
    "                if edge_attr_batch.shape[0] != len(src_ids):\n",
    "                    print(f\"Warning: edge_attr_batch shape {edge_attr_batch.shape} does not match src_ids length {len(src_ids)}\")\n",
    "                    continue\n",
    "                \n",
    "                with autocast():\n",
    "                    out = model(x, edge_index, edge_attr_batch, src_ids, dst_ids)\n",
    "                    loss = criterion(out, labels)\n",
    "                \n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                batch_loss += loss.item()\n",
    "                \n",
    "                del x, edge_index, edge_attr, pos_edges, neg_edges, src_ids, dst_ids, labels, out, edge_attr_batch\n",
    "                torch.cuda.empty_cache()\n",
    "                gc.collect()\n",
    "        \n",
    "        total_loss += batch_loss / len(batch_data)\n",
    "        del batch_data, batch_neg_samples\n",
    "        gc.collect()\n",
    "    \n",
    "    return total_loss / max(1, len(temporal_data) // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "506d82fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Visualization Functions ---\n",
    "def visualize_preprocessing_flow():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Preprocessing Flow Diagram\")\n",
    "    plt.text(0.1, 0.7, \"1. Load edges_train_A.csv with Dask\\n2. Create node mapping\\n3. Load node_features_sampled.csv\\n4. Load edge_type_features.csv\\n5. Load input_A_initial.csv\", fontsize=12)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(\"preprocessing_flow.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0dc52029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_temporal_snapshot(temporal_data):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.title(\"Temporal Snapshot Diagram\")\n",
    "    timestamps = [data.t for data in temporal_data]\n",
    "    plt.hist(timestamps, bins=50, edgecolor='black')\n",
    "    plt.xlabel(\"Timestamp\")\n",
    "    plt.ylabel(\"Snapshot Count\")\n",
    "    plt.savefig(\"temporal_snapshot.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02cc2239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_model_architecture():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.title(\"Model Architecture Diagram\")\n",
    "    plt.text(0.1, 0.7, \"TemporalLinkPredictor:\\n- Initial FC (Node Features)\\n- TGCN Layer\\n- Edge FC (Edge Features)\\n- Linear Output\", fontsize=12)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(\"model_architecture.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "31109361",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_embeddings(h, labels, title=\"Node Embeddings\"):\n",
    "    h = h.detach().cpu().numpy()\n",
    "    labels = labels.cpu().numpy()\n",
    "    z = TSNE(n_components=2).fit_transform(h)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.scatter(z[:, 0], z[:, 1], c=labels, cmap=\"Set2\", s=50)\n",
    "    plt.title(title)\n",
    "    plt.savefig(f\"{title.replace(' ', '_')}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3b693fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating preprocessing flow diagram...\n",
      "Preprocessing flow diagram saved as 'preprocessing_flow.png'\n",
      "\n",
      "Generating temporal snapshot diagram...\n",
      "Temporal snapshot diagram saved as 'temporal_snapshot.png'\n",
      "\n",
      "Generating model architecture diagram...\n",
      "Model architecture diagram saved as 'model_architecture.png'\n"
     ]
    }
   ],
   "source": [
    "# Generate visualizations\n",
    "print(\"\\nGenerating preprocessing flow diagram...\")\n",
    "visualize_preprocessing_flow()\n",
    "print(\"Preprocessing flow diagram saved as 'preprocessing_flow.png'\")\n",
    "\n",
    "print(\"\\nGenerating temporal snapshot diagram...\")\n",
    "visualize_temporal_snapshot(temporal_graph_sequence)\n",
    "print(\"Temporal snapshot diagram saved as 'temporal_snapshot.png'\")\n",
    "\n",
    "print(\"\\nGenerating model architecture diagram...\")\n",
    "visualize_model_architecture()\n",
    "print(\"Model architecture diagram saved as 'model_architecture.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5f8bdf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model...\n",
      "Epoch: 0, Loss: 0.3535\n",
      "Epoch: 1, Loss: 0.1781\n",
      "Epoch: 2, Loss: 0.1174\n",
      "Epoch: 3, Loss: 0.0913\n",
      "Epoch: 4, Loss: 0.0756\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining model...\")\n",
    "losses = []\n",
    "for epoch in range(5):\n",
    "    loss = train(model, temporal_graph_sequence, neg_samples_cache, optimizer, criterion, batch_size=64)\n",
    "    losses.append(loss)\n",
    "    print(f\"Epoch: {epoch}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        latest_graph = temporal_graph_sequence[-1]\n",
    "        x = latest_graph.x.to(device)\n",
    "        edge_index = latest_graph.edge_index.to(device)\n",
    "        edge_attr = latest_graph.edge_attr.to(device)\n",
    "        h = F.relu(model.initial_fc(x))\n",
    "        h = F.relu(model.tgcn(h, edge_index))\n",
    "        degrees = torch.bincount(latest_graph.edge_index[0], minlength=latest_graph.x.shape[0])\n",
    "        visualize_embeddings(h, degrees, f\"Node_Embeddings_Epoch_{epoch}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f9923a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(losses)\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.savefig(\"training_loss.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "abba679b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction on test data...\n"
     ]
    }
   ],
   "source": [
    "# --- Prediction ---\n",
    "print(\"\\nPrediction on test data...\")\n",
    "model.eval()\n",
    "output_a = []\n",
    "true_labels = []  # Gerçek etiketleri toplamak için\n",
    "predictions = []  # Tahminleri toplamak için\n",
    "edge_type_to_idx = {et: idx for idx, et in enumerate(edge_type_features_df[\"edge_type\"])}\n",
    "edge_type_features_tensor = torch.tensor(\n",
    "    edge_type_features_df.drop(columns=[\"edge_type\"]).values, dtype=torch.float32\n",
    ").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9ca885e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temporal_graph_sequence.sort(key=lambda x: x.t)\n",
    "snapshot_timestamps = [g.t for g in temporal_graph_sequence]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "90e39271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Snapshot timestamps range: min=1413662400, max=1494313200\n",
      "Input start_time range: min=1494579608, max=1498946320\n",
      "Number of start_times before earliest snapshot: 0\n",
      "Number of start_times after latest snapshot: 8196\n"
     ]
    }
   ],
   "source": [
    "print(f\"Snapshot timestamps range: min={min(snapshot_timestamps)}, max={max(snapshot_timestamps)}\")\n",
    "start_times = input_a_df[\"start_time\"].values\n",
    "print(f\"Input start_time range: min={start_times.min()}, max={start_times.max()}\")\n",
    "outside_range_before = sum(start_times < min(snapshot_timestamps))\n",
    "outside_range_after = sum(start_times > max(snapshot_timestamps))\n",
    "print(f\"Number of start_times before earliest snapshot: {outside_range_before}\")\n",
    "print(f\"Number of start_times after latest snapshot: {outside_range_after}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a5b1a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50\n",
    "num_batches = (len(input_a_df) + batch_size - 1) // batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "12b4c78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 164/164 [02:24<00:00,  1.13it/s]\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch_idx in tqdm(range(num_batches), desc=\"Predicting\"):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min(start_idx + batch_size, len(input_a_df))\n",
    "        batch_df = input_a_df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        src_ids = []\n",
    "        dst_ids = []\n",
    "        edge_types = []\n",
    "        start_times = []\n",
    "        labels = []  # Gerçek etiketleri toplamak için\n",
    "        batch_output = []\n",
    "        snapshots = []\n",
    "\n",
    "        for idx, row in batch_df.iterrows():\n",
    "            src_id = int(row[\"src_id\"])\n",
    "            dst_id = int(row[\"dst_id\"])\n",
    "            edge_type = int(row[\"edge_type\"])\n",
    "            start_time = row[\"start_time\"]\n",
    "            label = int(row[\"label\"])  # Label sütununu al\n",
    "            \n",
    "            if src_id >= num_nodes or dst_id >= num_nodes or src_id < 0 or dst_id < 0:\n",
    "                print(f\"Invalid node indices at row {start_idx + idx}: src_id={src_id}, dst_id={dst_id}, num_nodes={num_nodes}\")\n",
    "                batch_output.append(0.5)\n",
    "                continue\n",
    "            \n",
    "            relevant_history = None\n",
    "            for i in range(len(snapshot_timestamps) - 1, -1, -1):\n",
    "                if snapshot_timestamps[i] <= start_time:\n",
    "                    relevant_history = temporal_graph_sequence[i]\n",
    "                    break\n",
    "            \n",
    "            if relevant_history is None:\n",
    "                print(f\"No snapshot found for start_time={start_time} at row={start_idx + idx}, using latest snapshot\")\n",
    "                relevant_history = temporal_graph_sequence[-1]\n",
    "            \n",
    "            src_ids.append(src_id)\n",
    "            dst_ids.append(dst_id)\n",
    "            edge_types.append(edge_type)\n",
    "            start_times.append(start_time)\n",
    "            labels.append(label)  # Gerçek etiketi ekle\n",
    "            snapshots.append(relevant_history)\n",
    "            batch_output.append(None)\n",
    "        \n",
    "        if not src_ids:\n",
    "            output_a.extend([0.5 if x is None else x for x in batch_output])\n",
    "            gc.collect()\n",
    "            continue\n",
    "\n",
    "        src_ids_tensor = torch.tensor(src_ids, device=device)\n",
    "        dst_ids_tensor = torch.tensor(dst_ids, device=device)\n",
    "        \n",
    "        batch_size_valid = len(edge_types)\n",
    "        for i in range(batch_size_valid):\n",
    "            snapshot = snapshots[i]\n",
    "            x = snapshot.x.to(device)\n",
    "            edge_index = snapshot.edge_index.to(device)\n",
    "            edge_attr = torch.zeros((1, num_edge_features), dtype=torch.float32, device=device)\n",
    "            edge_type_idx = edge_type_to_idx.get(edge_types[i], 0)\n",
    "            edge_attr[0] = edge_type_features_tensor[edge_type_idx]\n",
    "            \n",
    "            src_id_tensor = src_ids_tensor[i:i+1]\n",
    "            dst_id_tensor = dst_ids_tensor[i:i+1]\n",
    "            with autocast():\n",
    "                out = model(x, edge_index, edge_attr, src_id_tensor, dst_id_tensor)\n",
    "                out = torch.sigmoid(out)  # Olasılık değerleri\n",
    "            batch_output[i] = out.item()\n",
    "            \n",
    "            # Gerçek etiket ve tahmini topla\n",
    "            true_labels.append(labels[i])  # Gerçek label’i kullan\n",
    "            predictions.append(out.item())\n",
    "        \n",
    "        batch_output = [0.5 if x is None else x for x in batch_output]\n",
    "        output_a.extend(batch_output)\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d9ac1fb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating AUC and plotting ROC curve...\n"
     ]
    }
   ],
   "source": [
    "# --- AUC Hesaplama ve ROC-AUC Grafiği ---\n",
    "print(\"\\nCalculating AUC and plotting ROC curve...\")\n",
    "all_labels = true_labels\n",
    "all_predictions = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8b159d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score (Overall): 0.5302\n"
     ]
    }
   ],
   "source": [
    "# ROC-AUC skoru hesapla\n",
    "roc_auc = roc_auc_score(all_labels, all_predictions)\n",
    "print(f\"AUC Score (Overall): {roc_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "56183c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC eğrisi ve optimal threshold\n",
    "fpr, tpr, thresholds = roc_curve(all_labels, all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0596ea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Threshold: 0.4014\n"
     ]
    }
   ],
   "source": [
    "# Optimal threshold'u bul (Youden's J istatistiği: TPR - FPR maksimize edilir)\n",
    "J = tpr - fpr\n",
    "optimal_idx = np.argmax(J)\n",
    "optimal_threshold = thresholds[optimal_idx]\n",
    "print(f\"Optimal Threshold: {optimal_threshold:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e7636fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC eğrisini çiz\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random Guess\")\n",
    "plt.scatter(fpr[optimal_idx], tpr[optimal_idx], color='red', label=f\"Optimal Threshold ({optimal_threshold:.2f})\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC-AUC Curve\")\n",
    "plt.legend()\n",
    "plt.savefig(\"roc_auc_curve.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "89b7dba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy at Optimal Threshold (0.4014): 0.5178\n"
     ]
    }
   ],
   "source": [
    "# Optimal threshold ile doğruluk hesapla\n",
    "predictions_binary = [1 if p >= optimal_threshold else 0 for p in all_predictions]\n",
    "accuracy = sum(1 for true, pred in zip(all_labels, predictions_binary) if true == pred) / len(all_labels)\n",
    "print(f\"Accuracy at Optimal Threshold ({optimal_threshold:.4f}): {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d4c50824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving trained model...\n",
      "Model saved as 'trained_model.pth'\n"
     ]
    }
   ],
   "source": [
    "# --- Save Model ---\n",
    "print(\"\\nSaving trained model...\")\n",
    "torch.save(model.state_dict(), \"trained_model.pth\")\n",
    "print(\"Model saved as 'trained_model.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d256c088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving output...\n",
      "Output saved to output_a.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4274"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Save Output ---\n",
    "print(\"\\nSaving output...\")\n",
    "output_df = pd.DataFrame({\"probability\": output_a})\n",
    "output_df[\"probability\"] = output_df[\"probability\"].astype(float)\n",
    "output_df.to_csv(\"output_a.csv\", index=False, header=False, na_rep=\"0.5\")\n",
    "print(\"Output saved to output_a.csv\")\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d077f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc83086",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede10b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
